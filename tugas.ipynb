{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indmind/2141720003-machine-learning-2023/blob/main/tugas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSra1GNFAhSS"
      },
      "source": [
        "# **Praktikum 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dUFprmpMPQxM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v8juYg4gParT"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf72ysIBPnZS",
        "outputId": "3238b7b3-73b8-4774-980e-6862fe38d84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membaca teks dari file menggunakan mode 'rb' (binary mode) dan mendekode dengan encoding 'utf-8'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Panjang teks adalah jumlah karakter dalam teks tersebut\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6z_nd1PwL4",
        "outputId": "829f64db-6308-4777-a8ef-6ab04edf7967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mencetak 250 karakter pertama dalam teks\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtzwyfLwP5h0",
        "outputId": "73929077-0e3e-4d1f-a8fa-529c851cd961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Mengidentifikasi karakter-karakter unik dalam teks\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Mencetak jumlah karakter unik\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDBxzkrQKsA",
        "outputId": "aa47522f-9564-4b52-b052-73d477e9a29a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Daftar teks contoh\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "# Memecah teks menjadi karakter-karakter Unicode\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "# Menampilkan hasil karakter-karakter Unicode\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxWcI0H2QUw0"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "veQAl0_IQY8q"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi karakter menjadi ID numerik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),  # Daftar karakter-karakter yang ingin diindeks\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx7lpw8-QcM3"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c1g-evjQhGS",
        "outputId": "2e3e995c-86be-42c0-a85a-7754747b093f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Mengonversi karakter-karakter Unicode menjadi ID numerik\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "# Menampilkan hasil ID numerik\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME_l5PHOQpdR"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode\n",
        "`tf.keras.layers.StringLookup(..., invert=True)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WwZ30hnfQwoR"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi ID numerik ke karakter-karakter Unicode\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),  # Menggunakan vocabulary yang telah diindeks sebelumnya\n",
        "    invert=True,  # Mengatur invert ke True untuk mengonversi kembali dari ID ke karakter\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1UwK4TjQ07J"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter `tf.RaggedTensor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkMaj34Q4AI",
        "outputId": "751274b4-e05e-412b-b166-e782394631f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mZECFZ3kQ_yo"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDGcG_FjRQMs",
        "outputId": "212aed02-ca18-4cbc-bb17-35576195b19b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XvyfN2thRVoN"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1BB9b9WRYVh",
        "outputId": "5f7c68f4-08b3-453d-a2b1-595464d67dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wJVh5A5sRfaN"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g0Ujf0pRj5M"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x23Xhs9RkwQ",
        "outputId": "61aa28c0-6177-4b93-ce15-1d183bc1a77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnu7qzuMRnFP"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHzIPIE4RoB8",
        "outputId": "a7d6d833-4630-4ab9-aee0-d54ccb335ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFKNsuSQR2yP"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GFrhhXHJR3yL"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4JjXTHBR7be",
        "outputId": "e40ac644-7c9e-43f0-8557-399db521343d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AhQ2Oy2iR8M7"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbMBcM-R_Bv",
        "outputId": "08e37628-84a4-4212-8c4a-54a4c7cd2170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-naOjirSSMSn"
      },
      "source": [
        "### **Membuat Batch Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZuuXPD3SP7m"
      },
      "source": [
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r7F3Z-hSYyR",
        "outputId": "b5d72069-cbbf-45de-fb4e-7ad3eab3bfa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Batch size (ukuran batch) yang digunakan selama pelatihan\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size (ukuran buffer) untuk mengacak urutan dataset\n",
        "# TensorFlow data dirancang untuk bekerja dengan urutan yang mungkin tak terbatas,\n",
        "# sehingga tidak mencoba untuk mengacak seluruh urutan di dalam memori.\n",
        "# Sebaliknya, ia mempertahankan buffer di mana ia mengacak elemen.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Mengonfigurasi dataset dengan mengacak urutan, mengatur ukuran batch,\n",
        "# dan menggunakan prefetch untuk optimalisasi\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)  # Mengacak urutan dataset\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)  # Mengatur ukuran batch dengan menghapus sisa data yang tidak cukup untuk satu batch\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)  # Menggunakan prefetch untuk optimalisasi\n",
        ")\n",
        "\n",
        "# Menampilkan dataset yang telah dikonfigurasi\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNKbrvteSa3v"
      },
      "source": [
        "### **Buat Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uJxbIwxjSkOG"
      },
      "outputs": [],
      "source": [
        "# Jumlah kata dalam vocabulary pada lapisan StringLookup\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Jumlah unit RNN (Recurrent Neural Network)\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DydDIKuASqjF"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan kelas model khusus MyModel\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "\n",
        "    # Lapisan embedding untuk mengonversi ID numerik menjadi vektor embedding\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # Lapisan GRU (Gated Recurrent Unit) dengan return_sequences dan return_state\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "    # Lapisan dense (sepenuhnya terhubung) dengan vocab_size output\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # Menggunakan lapisan embedding\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    if states is None:\n",
        "      # Mendapatkan initial_state dari lapisan GRU jika states adalah None\n",
        "      states = self.gru.get_initial_state(x)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan dense\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      # Mengembalikan output dan states jika return_state adalah True\n",
        "      return x, states\n",
        "    else:\n",
        "      # Mengembalikan hanya output jika return_state adalah False\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3judqwFWSwSc"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,  # Jumlah kata dalam vocabulary\n",
        "    embedding_dim=embedding_dim,  # Dimensi embedding\n",
        "    rnn_units=rnn_units  # Jumlah unit dalam lapisan GRU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6_3dZu1TRHx"
      },
      "source": [
        "### **Uji Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXejIFiBTTVv",
        "outputId": "26891e27-3f8b-4c37-f112-ac575ee6ad48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtiHr-0aTVK2",
        "outputId": "ee0a415a-17df-409c-c7d3-307a0a8cfa92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FYHNdbLGTgQx"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices= tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xYyKv1TiVL",
        "outputId": "11086205-e9a3-449d-f5ff-73c5be4727ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([34,  2, 11, 31,  8,  2, 22,  8, 49, 18,  6, 20, 19,  7, 55, 50, 12,\n",
              "       57, 28, 14,  8, 23, 18, 18, 37, 29, 60, 24, 41, 10,  6, 56, 65,  9,\n",
              "        7, 57, 24, 11, 52, 15, 63,  8, 58, 48, 48, 44, 32, 45, 24, 51,  2,\n",
              "       34, 50, 26, 61, 36, 24, 24, 62, 18, 56,  4, 62, 28, 20, 24, 59, 10,\n",
              "       37,  2, 36,  4, 39, 21, 45, 47, 14,  2, 45, 39, 52, 20, 49, 14, 46,\n",
              "       27, 49, 64, 21, 49, 19, 38, 27, 44,  4, 17, 22, 33, 51, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBYtrOMKTlSg"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3lFhz1FTmOO",
        "outputId": "d5105be9-8163-4d0b-f06f-9c342e7f2ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\", thus accused it:\\nThat only like a gulf it did remain\\nI' the midst o' the body, idle and unactive,\\n\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"U :R- I-jE'GF,pk;rOA-JEEXPuKb3'qz.,rK:mBx-siieSfKl UkMvWKKwEq$wOGKt3X W$ZHfhA fZmGjAgNjyHjFYNe$DITlS\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHU0EFcvTqhZ"
      },
      "source": [
        "### **Train Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiEIJa9mTugb"
      },
      "source": [
        "### **Tambahan optimizer dan fungsi loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ianM1LzsTyZN"
      },
      "source": [
        "loss function `tf.keras.losses.sparse_categorical_crossentropy` standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag `from_logits`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "r3NS4010Txiv"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awXsdeo5T2_S",
        "outputId": "5a539c11-45ac-4bba-b919-3a38b8378217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1912813, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkVK_SRlT57q"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8oak6NTT66X",
        "outputId": "1023b131-8297-4596-c98e-1de19bdbbde5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.107445"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15l9xvf_T8Z4"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gEzgfJ_fT9Ou"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAmC2i2MUAz6"
      },
      "source": [
        "### **Konfigurasi Checkpoints**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5FE1URUEVw"
      },
      "source": [
        "Gunakan `tf.keras.callbacks.ModelCheckpoint` untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f5DaoAtKUCy3"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wfkMnSyUH4j"
      },
      "source": [
        "### **Lakukan Proses Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Tr2Prky1UKsm"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b21Ke52aUMeI",
        "outputId": "ee7fa621-955f-4184-d1a8-7eff7e220b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 14s 54ms/step - loss: 2.7011\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.9792\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.6993\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.5406\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.4438\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3766\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3235\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.2794\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.2372\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.1978\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpRHmPcKUb1d"
      },
      "source": [
        "### **Generate Teks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQKIdpGNVhNY"
      },
      "source": [
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qJ0D-kcDVh6d"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GDJ5Yg8AVkwg"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcHnIK2Vpka",
        "outputId": "170bdfac-f2dd-40ad-a381-7923fd9c7bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "How is three news?\n",
            "\n",
            "Provost:\n",
            "How most awsicious cripiness' nor and bloody\n",
            "To same your lordages the doom; Catesby:\n",
            "Strike up in his pillaiment: therefore, so,\n",
            "Then but so well his punish propity, hell, buy learning such a\n",
            "cause. thou wouldst thou, grazegly!\n",
            "Year, my grazed mother much.\n",
            "His swafe, to the laws.\n",
            "\n",
            "RICHARD:\n",
            "Nay, he had noted both you pale as language,\n",
            "Let's have by this stoopport suddemank. Now, Clifford,\n",
            "Look in the first of at as pire to pleasing.\n",
            "\n",
            "BISHOP OF CARLISLE:\n",
            "Thou did it? You of all things all:\n",
            "Therefore at reason isleep, that was hootlock and as being cannot\n",
            "While Lewis for as at thought it makes.\n",
            "\n",
            "RIVERS:\n",
            "Hoars Prince, you are remainded in talkeh;\n",
            "Old Kate, by Gid, 'for he stay than calms him her in hip vow?\n",
            "No, Norfel, powers us for me. For thy now I did.\n",
            "\n",
            "QUEEN RATER:\n",
            "Surrey, About o'er his highness of my censure,\n",
            "Which not used him.\n",
            "\n",
            "PROSPERO:\n",
            "Ay, if my suit: dishing me would have paids of door\n",
            "And in their lamentation.\n",
            "\n",
            "FRIAR JOHN:\n",
            "I mean, my lord, you rat \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.8487348556518555\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20crZVvJVuYs",
        "outputId": "415f0f9a-5447-4662-aa95-00cb6190407c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO: the present prince of hath some hearts to fault.\\n\\nPETRUCHIO:\\nResice the mark that of my unrequerness death\\nIs bedis; two despite, sure, let it; 'twas a meddlers.\\n\\nANGELO:\\nCome to the Warwick, have any leave?\\n\\nANTONIO:\\nTell him with greater to be; for they resort it, and\\nBy name. God sir, if Kiss Gidrom prevosion.\\nOr else my ancient shapes of me in blood,\\nThat will were the lasque than I should find.\\nCay she hath, good from Rome as thought and fetch'd\\nindeed kiss in thine own eyes, and that she there no puts\\nBitter to the king's subbloces, him, you have\\ngentorsign and lawfully ligst making\\nTebles of his necks? ORWARD IV:\\nGust weep, and for this world,\\nGod--knick are three and his sun beastsion of his king.\\nHad should cumbs swear it out, 'tis mine:\\nWho father what i' the lies tongues\\nHave kill'd me your fitches, sir, and but sweet'st friendly,\\nTo be the sky, om bittorke grows some broble time,\\nHortension of a gracious tears never-finded,\\nI love it infitmy blossing soundly threat?\\nA son \"\n",
            " b\"ROMEO:\\nGod saint thee accuse the day, the tears are or,\\nTo more, Angelo. Come on,\\nWhile he not? Grindess. What, is he\\nDispate my counsel and good thing to death the\\nmed! when this way, my hair shall be of each came.\\nWhat each orpeese had fairous and I was;\\nFor I am nothing, nine to the stroke of officer,\\nAs thus great will of Allow; I do it: neither pity\\nAs crowned be u'les to our traitor sprighth:\\nAmen and so infit to sa?\\n\\nPROSPERO:\\nWhat sard him whom,\\nTo do the liar earth, he lies us time to whom\\nI seem'd our one as grain upon my boats,\\nStand hit at once, and unpety and citizensure stoop\\nTo true are shook of coloces.\\n\\nMARCIUS:\\nWere, sir, a\\ntorch-barrewing approthess; i'll if you well.\\n\\nMARCIUS:\\nSo do I do see the proudest, son!\\nA woman on ears, which if all of your counterly\\ncensues? to put you to wearself\\nHatch in my butts are well for reasons in their cick'd.\\nTake thou likertion. Be too foe:\\nWhy, the cointedom in a heavy seat,\\nHe stands your high dispersoral't.\\nLacked Misasianly made bef\"\n",
            " b\"ROMEO:\\nContent it there; 'tis too?\\n\\nRICHARD:\\nA noble temples: bless a merry weepful nebtre\\nOf son of jedgune, if he needs make\\nthink fluts; but hang his grave carle so gluss: 'twas my need noses;\\nAnd he make thee, good fall of Wells,\\nHe canesby, not incensir's the pither's bable;\\nI'll well in Cadabuines, but assistancy\\nAssembory and clusho, let him strike:\\nAnd, friar, for one that trouble this hour.\\n\\nSICINIUS:\\nWhat, rack,\\nIn his good years so worry, tell him, he shall solemploss\\nTrows be no strange runable as a\\nClifford from my part on't.\\n\\nCAMILLO:\\nI am preparaties,\\nEven never as giedned hand so deep!\\nThoughts up his tear.\\n\\nGLOUCESTER:\\nHaply and speak back af ormedly.\\n\\nMERCUTIO:\\nIf now! when you darest not dough find\\nOr one read to wedding in right\\nnamed, sir, a toxe of me King of his name hath awed.\\nWhat, is this wedding your countenawe of a goodly.\\n\\nNORTHUMBERLAND:\\nWell, I dark nothing; but he will be disguar'd\\nTo do atterna, and there that you dream'mert be?\\n\\nLUCIO:\\nCome, come.\\n\\nPROSPERO:\"\n",
            " b\"ROMEO:\\nBut sleep is, I'll be a husband nown, grows, I say, sir,\\nWhat's he? quoth he that shall before your body.\\nI prithee your grace, there therein now friends.\\n\\nBUCKINGHAM:\\nHark you! Bolingbroble him, and process to Rome,\\nIs rolemy to infaint this oll than with thee.\\n\\nJULIET:\\nBefore thou wilt not make thy commonws relice?\\n\\nRICHARD:\\nAy, a good before I lip the life;\\nBut, sooner Rome:\\nI'll make you both: our grace with beaving life,\\nOn the seluse of your busiress of this pleasure:\\nLest I am too but your castable:\\nSo, now become us with grief, hand him against yea: as he\\nknows her Angelo; and thou didst low with him,\\nThe rest best know what his once perfumed\\nThe heartsing since they come watch.\\nShe was one rather. CHENRY BOLINGBROKE:\\nI warrant, wept to to be cozentlaining, and balidees,\\nI do confess besire; let us he\\ncan see ' harm, that looks her dybal I did believe\\nnothing but a-true nobly\\nMy creature and pursted me. Can you him?\\n\\nProvost:\\n\\nCORIOLANUS:\\nBaliance, bear did enough-faced wasted\"\n",
            " b\"ROMEO:\\nI must do,--that thou mayst meaner and enduined,\\nI'll make an hourly beauty you depart.\\n\\nKING RICHARD III:\\nHere is, it, being all to claim the holy or be, Romeo!\\nIn God's case with Richard!'\\nThis line hand think to grace the time.\\nTake it as more than with Lancaster,\\nI will give us retainted in me his fround.\\nIf thy scarler in this pergedon, that\\nAumerle, Norfolk in it?--\\nA-covert to the belly, how now?\\nThey did it be not, there giddy new-cracking jeins,\\nIs musin Ramens of Lancaster\\nToo heavy in She's blows. Case the time o' Ay:\\nThe city safe spirit how to do my son-well;\\nSweet I, my lord. Was it tream in blush,--\\nBut choourable sun as like a dream word,\\nWith mine enamions do orportain:\\nLet me any Hanting-sick and find\\nThan Gods, then give\\nThan a man had wint the hour interewe advantage.\\n\\nQUEEN MARGARET:\\nO, fetch you plead escale? fellow him.\\n\\nCURTIS:\\nAy, but of all hate.\\n\\nCOMINIUS:\\nThis is your profrect strength.\\n\\nKING EDWARD IV:\\nWithin the meaners charged her on my curse;\\nWho here i\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.232889175415039\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnIQu9_FVzFf"
      },
      "source": [
        "### **Ekspor Model Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4SCw-2fV363",
        "outputId": "80ae396c-d43e-470e-bdf8-cc4fef21b023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7ef5223d27d0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVVLwLO8V5rR",
        "outputId": "64e7a40a-c5fc-4a56-d152-3f12bca001f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "O miserable!\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Come, the pitient of the matches too poor dear;\n",
            "I prityed go duke on\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsKUeogIdioh"
      },
      "source": [
        "# **Praktikum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUZK_lhGdoA-"
      },
      "source": [
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan `tf.GradientTape` untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca `eager execution guide`.\n",
        "\n",
        "Prosedurnya adalah:\n",
        "1. Jalankan Model dan hitung loss dengan `tf.GradientTape`.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5QnA9TlJgDnO"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        " @tf.function\n",
        " def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "        predictions = self(inputs, training=True)\n",
        "        loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AkHzj9SOgKVz"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "     vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "     embedding_dim=embedding_dim,\n",
        "     rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EN2PlZ_HgQeM"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo8tekFgUCf",
        "outputId": "aec78f1f-8104-4092-fb8d-9c1f3baa5d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 16s 59ms/step - loss: 2.7391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef51811ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4eAUrwLgcjG",
        "outputId": "3bcd3ee4-9491-4178-c0a7-6672b58644da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1868\n",
            "Epoch 1 Batch 50 Loss 2.0835\n",
            "Epoch 1 Batch 100 Loss 2.0028\n",
            "Epoch 1 Batch 150 Loss 1.8626\n",
            "\n",
            "Epoch 1 Loss: 2.0059\n",
            "Time taken for 1 epoch 13.86 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8342\n",
            "Epoch 2 Batch 50 Loss 1.7534\n",
            "Epoch 2 Batch 100 Loss 1.6716\n",
            "Epoch 2 Batch 150 Loss 1.6631\n",
            "\n",
            "Epoch 2 Loss: 1.7238\n",
            "Time taken for 1 epoch 20.48 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.6145\n",
            "Epoch 3 Batch 50 Loss 1.6119\n",
            "Epoch 3 Batch 100 Loss 1.5056\n",
            "Epoch 3 Batch 150 Loss 1.5226\n",
            "\n",
            "Epoch 3 Loss: 1.5553\n",
            "Time taken for 1 epoch 11.49 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4745\n",
            "Epoch 4 Batch 50 Loss 1.4416\n",
            "Epoch 4 Batch 100 Loss 1.4486\n",
            "Epoch 4 Batch 150 Loss 1.4265\n",
            "\n",
            "Epoch 4 Loss: 1.4532\n",
            "Time taken for 1 epoch 11.46 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4052\n",
            "Epoch 5 Batch 50 Loss 1.4249\n",
            "Epoch 5 Batch 100 Loss 1.3430\n",
            "Epoch 5 Batch 150 Loss 1.3411\n",
            "\n",
            "Epoch 5 Loss: 1.3839\n",
            "Time taken for 1 epoch 43.85 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3314\n",
            "Epoch 6 Batch 50 Loss 1.3427\n",
            "Epoch 6 Batch 100 Loss 1.3554\n",
            "Epoch 6 Batch 150 Loss 1.3530\n",
            "\n",
            "Epoch 6 Loss: 1.3313\n",
            "Time taken for 1 epoch 12.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2737\n",
            "Epoch 7 Batch 50 Loss 1.2704\n",
            "Epoch 7 Batch 100 Loss 1.3154\n",
            "Epoch 7 Batch 150 Loss 1.3046\n",
            "\n",
            "Epoch 7 Loss: 1.2856\n",
            "Time taken for 1 epoch 12.54 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2668\n",
            "Epoch 8 Batch 50 Loss 1.2572\n",
            "Epoch 8 Batch 100 Loss 1.2586\n",
            "Epoch 8 Batch 150 Loss 1.2636\n",
            "\n",
            "Epoch 8 Loss: 1.2449\n",
            "Time taken for 1 epoch 12.29 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1615\n",
            "Epoch 9 Batch 50 Loss 1.1669\n",
            "Epoch 9 Batch 100 Loss 1.2174\n",
            "Epoch 9 Batch 150 Loss 1.2111\n",
            "\n",
            "Epoch 9 Loss: 1.2042\n",
            "Time taken for 1 epoch 11.52 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1044\n",
            "Epoch 10 Batch 50 Loss 1.1511\n",
            "Epoch 10 Batch 100 Loss 1.1985\n",
            "Epoch 10 Batch 150 Loss 1.2212\n",
            "\n",
            "Epoch 10 Loss: 1.1639\n",
            "Time taken for 1 epoch 44.04 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "      logs = model.train_step([inp, target])\n",
        "      mean.update_state(logs['loss'])\n",
        "\n",
        "      if batch_n % 50 == 0:\n",
        "         template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "         print(template)\n",
        "\n",
        " # saving (checkpoint) the model every 5 epochs\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "         model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAAXWAktm805"
      },
      "source": [
        "**Perbedaan dengan praktikum 2?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs5OMckAsQAS"
      },
      "source": [
        "Dalam praktikum 2, digunakan metode pelatihan yang lebih umum dan sederhana, yaitu model.fit, yang telah terintegrasi dengan TensorFlow. Metode ini secara otomatis mengelola banyak aspek pelatihan, termasuk perhitungan loss, perhitungan gradien, dan pembaruan bobot model.\n",
        "\n",
        "Di sisi lain, dalam tugas praktikum yang diberikan, digunakan pendekatan pelatihan yang lebih spesifik dan kompleks. Dalam pendekatan ini, ada penggunaan metode train_step yang didefinisikan secara eksplisit dalam turunan model. Metode ini mengendalikan perhitungan loss, perhitungan gradien, dan pembaruan bobot model dengan jelas. Selain itu, ada penggunaan objek tf.metrics.Mean untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan tingkat kontrol yang lebih tinggi dan lebih banyak opsi kustomisasi dalam proses pelatihan model.\n",
        "\n",
        "Secara keseluruhan, perbedaan utama antara kedua pendekatan ini terletak pada tingkat kontrol yang lebih tinggi dan lebih banyak fleksibilitas yang diberikan oleh kode dalam tugas praktikum. Hal ini sangat bermanfaat ketika Anda perlu menyesuaikan pelatihan model secara khusus untuk tugas-tugas tertentu."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}